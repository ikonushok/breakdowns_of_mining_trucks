import os

import pandas as pd
from pathlib import Path

from auxiliary.utils_minigng_trucks import setup_pandas_options, save_parquet, optimize_dtypes

setup_pandas_options()

def data_cleaner(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = df.columns.str.strip()  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏–ª–∏ —Å–∏–º–≤–æ–ª—ã –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏
    df.replace(-1000000, pd.NA, inplace=True)  # –ó–∞–º–µ–Ω–∏–º -1000000 –Ω–∞ NaN
    df = df.dropna(how='all', axis=0)  # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    df = df.dropna(how='all', axis=1)  # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]  # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å Unnamed

    # –£–¥–∞–ª–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏, –≥–¥–µ –Ω–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è..
    nunique = df.nunique()
    zero_variance_cols = nunique[nunique <= 1].index.tolist()
    print("–ë–µ—Å–ø–æ–ª–µ–∑–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:", zero_variance_cols)
    df = df.drop(columns=zero_variance_cols)

    return df


source_root = 'dataset/_by_Hack'

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
print(f'\nidles:')
idles = pd.read_csv(f'{source_root}/reference/idles.csv')
idles = data_cleaner(idles)
print(idles)

idles['GMTBEGINTIME'] = pd.to_datetime(idles['GMTBEGINTIME'], errors='coerce')
idles = idles.dropna(subset=['GMTBEGINTIME'])

idles = idles.rename(columns={
    'OBJECTID': 'asset_id',
    'GMTBEGINTIME': 'event_time',
    'IDLETYPENAME': 'event_name',
    'OBJECTNAME': 'mdm_object_name'
})
print(pd.unique(idles['event_name']))

event_to_case = {
    # üîπ –ö–µ–π—Å 1: –¢–æ–ø–ª–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞
    '–¢–æ–ø–ª–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞': 'fuel_degradation',
    # '–ó–∞–º–µ–Ω–∞ —Ñ–æ—Ä—Å—É–Ω–∫–∏': 'fuel_degradation',
    # '–†–µ–º–æ–Ω—Ç –¢–ù–í–î': 'fuel_degradation',

    # # üîπ –ö–µ–π—Å 2: –ù–∞–¥–¥—É–≤ / —Ç—É—Ä–±–æ–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä
    # '–ì–∏–¥—Ä–∞–≤–ª–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞': 'turbo_degradation',
    # '–ü–Ω–µ–≤–º–æ—Å–∏—Å—Ç–µ–º–∞': 'turbo_degradation',
    # '–°–Ω–∏–∂–µ–Ω–∏–µ –¥–∞–≤–ª–µ–Ω–∏—è –Ω–∞–¥–¥—É–≤–∞': 'turbo_degradation',

    # # üîπ –ö–µ–π—Å 3: –û—Ö–ª–∞–∂–¥–µ–Ω–∏–µ
    # '–°–∏—Å—Ç–µ–º–∞ –æ—Ö–ª–∞–∂–¥–µ–Ω–∏—è': 'cooling_failure',
    # '–ü—Ä–æ–∫–∞—á–∫–∞ –ü–ì–ü': 'cooling_failure',
    # '–ù–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç—å –Ω–∞—Å–æ—Å–∞': 'cooling_failure',

    # # üîπ –ö–µ–π—Å 4: –ú–∞—Å–ª–æ
    # '–ü–µ—Ä–µ–≥—Ä–µ–≤ –ö–ì–®': 'oil_pressure_drop',
    # '–ö–ì–® - –∑–∞–º–µ–Ω–∞': 'oil_pressure_drop',
    # '–ù–∏–∑–∫–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ –º–∞—Å–ª–∞': 'oil_pressure_drop',

    # # üîπ –ö–µ–π—Å 5: –≠–ª–µ–∫—Ç—Ä–æ—Ç—è–≥–∞
    # '–†–µ–º–æ–Ω—Ç –ê–°–î': 'electric_failure',
    # '–ù–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç—å –ê–°–î': 'electric_failure',
    # '–û—Ç–∫–∞–∑ –∏–Ω–≤–µ—Ä—Ç–æ—Ä–∞': 'electric_failure',

    # # üîπ –ö–µ–π—Å 6: –¢—Ä–∞–Ω—Å–º–∏—Å—Å–∏—è
    # '–•–æ–¥–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞': 'gearbox_overheat',
    # '–†–µ–º–æ–Ω—Ç —Ä–µ–¥—É–∫—Ç–æ—Ä–∞': 'gearbox_overheat',

    # # üîπ –ö–µ–π—Å 7: –®–∏–Ω—ã
    # '–ö–ì–® - –ø–æ–¥–∫–∞—á–∫–∞': 'tire_burst_risk',
    # '–£—Ç–µ—á–∫–∞ –≤–æ–∑–¥—É—Ö–∞ –≤ —à–∏–Ω–µ': 'tire_burst_risk',

    # # üîπ –ö–µ–π—Å 8: –í–æ–∑–¥—É—à–Ω—ã–π —Ç—Ä–∞–∫—Ç
    # '–¢–û, –ö–†, –ü–ü–†': 'air_filter_clogged',
    # '–ó–∞–º–µ–Ω–∞ –≤–æ–∑–¥—É—à–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞': 'air_filter_clogged',

    # # üîπ –ö–µ–π—Å 9: –†–µ–∂–∏–º—ã –≤–æ–∂–¥–µ–Ω–∏—è
    # '–û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–≥—Ä—É–∑–∫–∏': 'aggressive_driving',
    # '–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—Ä–∞–≤–∫–∏ - –æ—á–µ—Ä–µ–¥—å': 'aggressive_driving',
    # '–û–∂–∏–¥–∞–Ω–∏–µ —Ä–∞–∑–≥—Ä—É–∑–∫–∏': 'aggressive_driving'

}

# –ü—Ä–∏–º–µ–Ω—è–µ–º
idles['case'] = idles['event_name'].map(event_to_case)
idles_events = idles.dropna(subset=['case'])[['asset_id', 'mdm_object_name', 'event_time', 'case']].drop_duplicates()

idles_df_optimized = optimize_dtypes(idles_events)
save_parquet(idles_df_optimized, Path('dataset/ml_datasets/_by_Hack/idles.parquet'))
print(idles_df_optimized)


# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –º–∞—Å–ª—è–Ω–æ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏
print(f'\noil_lab_df:')
oil = pd.read_csv(f'{source_root}/oil/oil.csv')
oil = data_cleaner(oil)

oil['TakenDate'] = pd.to_datetime(oil['TakenDate'], errors='coerce')
oil = oil.dropna(subset=['TakenDate'])

oil = oil.rename(columns={
    'UnitNumberField': 'mdm_object_name',
    'TakenDate': 'event_time'
})

if 'ComponentTypeField' in oil.columns:
    oil = oil[oil['ComponentTypeField'].str.contains('–¥–≤–∏–≥–∞—Ç–µ–ª—å|engine', case=False, na=False)]

oil['is_oil_issue'] = oil['Condition'].isin(['Abnormal', 'Severe'])
oil_issues = oil[oil['is_oil_issue']].copy()
oil_issues['case'] = 'oil_pressure_drop'
oil_issues = oil_issues[['mdm_object_name', 'event_time', 'case']].drop_duplicates().reset_index(drop=True)

manual_mapping = {
    1374: 1383,
    1381: 1581,
    1349: 1381,
    1497: 2186,
    1385: 1384,
    1395: 1661,
}
oil_issues['asset_id'] = oil_issues['mdm_object_name'].map(manual_mapping)

oil_lab_df_optimized = optimize_dtypes(oil_issues)
save_parquet(oil_lab_df_optimized, Path('dataset/ml_datasets/_by_Hack/oil_lab_df.parquet'))
print(oil_lab_df_optimized)



# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏
files = os.listdir(f'{source_root}/telemetry')
print(f'\ntelemetry_df:')
print(files)
data_frames = []
for file in files:
    if 'telemetry' in file and file.endswith('.csv'):
        print(f'Loading {file} for combine..')
        df = pd.read_csv(os.path.join(f'{source_root}/telemetry', file))
        df = optimize_dtypes(df)

        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö
        df.columns = df.columns.str.strip()

        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º
        df = df.rename(columns={
            'mdm_object_id': 'asset_id',
            'create_dt': 'timestamp',
            'load_engine': 'engine_load',
            'inst_fuel': 'fuel_rate',
            'pres_rail_injector_nn': 'rail_pressure',
            'pres_des_rail_injector_nn': 'rail_pressure_target',
            'pres_turbo': 'boost_pressure',
            'engine_coolant_temp': 'coolant_temp',
            'engine_oil_pressure': 'oil_pressure',
            'temp_oil_engine_nn': 'oil_temp',
            'tweather_nn': 'ambient_temp',
            'speed_gps': 'vehicle_speed',
            'spn': 'fault_code'
        })

        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        df = df.drop(columns=[
            'Unnamed: 0',
            'engine_speed_control',
            'finjection',
            'purgepressure_nn',
            'meta_object_name',
            'meta_model_id',
            'ambient_temp',
            'mdm_object_uuid',
            'mdm_model_id',
            'oil_temp',
            'boost_pressure',
            'meta_model_name',
            'sutep_error',
            'fault_code',
            'distance_nn',
            'fault_code',
            'engine_rpm',
            # 'mdm_object_name',
            'mdm_model_name',
            'coefficient_correction',
            'error_belaz_11',
            'error_belaz_12',
            'fault_code',
            'fmi',
            'spn_weichai',
            'accelerator_pedal_position',
            'transmission_oil_temperature',
            'coefficient_correction',
            'total_vehicle_hours',
            'nominal_torque',
            'fuel_level_can',
            'turbo_pressure',
            'crankcase_purge_pressure',
            'engine_oil_level',
            'coolant_temp',
            'oil_pressure',
            'dfm_in_sum'
        ], errors='ignore')

        # –ü—Ä–∏–≤–æ–¥–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
        df = df.dropna(subset=['timestamp'])

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
        df = df.drop_duplicates(subset=['asset_id', 'timestamp'])

        data_frames.append(df)

print('–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö DataFrame –≤ –æ–¥–∏–Ω..')
telemetry_df = pd.concat(data_frames, ignore_index=True)





print('–£–¥–∞–ª–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏, –≥–¥–µ –Ω–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è..')
telemetry_df = data_cleaner(telemetry_df)
telemetry_df_optimized = optimize_dtypes(telemetry_df)
print('save_parquet..')
save_parquet(telemetry_df_optimized, Path('dataset/ml_datasets/_by_Hack/telemetry_df.parquet'))
print(telemetry_df_optimized)
